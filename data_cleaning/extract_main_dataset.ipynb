{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct dataset for MIMIC analysis\n",
    "\n",
    "Note:  MIMIC-ED should be downloaded at “data/ed\" folder (please see the README for more instructions).  \n",
    "\n",
    "This code is adapted from https://github.com/rmovva?tab=repositories, which was in turn adapted from https://github.com/nliulab/mimic4ed-benchmark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Python library and raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload packages from notebook whenever needed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data/cb/shuvom/funnels/repo/data_cleaning')\n",
    "\n",
    "from helpers import *\n",
    "from medcode_utils import comorbidity, extract_icd_list\n",
    "from paths import mimic_iv_path, data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define auxillary paths/files\n",
    "# 'ed' subfolder should also be added to mimic_iv_path\n",
    "mimic_iv_core_path = os.path.join(mimic_iv_path, 'hosp')\n",
    "mimic_iv_hosp_path = os.path.join(mimic_iv_path , 'hosp')   \n",
    "mimic_iv_icu_path = os.path.join(mimic_iv_path, 'icu')\n",
    "mimic_iv_ed_path = os.path.join(mimic_iv_path, 'ed')\n",
    "\n",
    "# Use gzipped filepaths for auxiliary MIMIC data\n",
    "icu_filename_dict = {\"chartevents\":\"chartevents.csv.gz\", \"datetimeevents\":\"datetimeevents.csv.gz\",\"d_items\":\"d_items.csv.gz\",\"icustays\":\"icustays.csv.gz\",\"inputevents\":\"inputevents.csv.gz\",\"outputevents\":\"outputevents.csv.gz\",\"procedureevents\":\"procedureevents.csv.gz\"}\n",
    "core_filename_dict = {\"patients\":\"patients.csv.gz\", \"admissions\":\"admissions.csv.gz\", \"transfers\":\"transfers.csv.gz\"}\n",
    "hosp_filename_dict = {\"d_hcpcs\":\"d_hcpcs.csv.gz\",\"d_icd_diagnoses\":\"d_icd_diagnoses.csv.gz\",\"d_labitems\":\"d_labitems.csv.gz\",\"emar\":\"emar.csv.gz\",\"hcpcsevents\":\"hcpcsevents.csv.gz\",\"microbiologyevents\":\"microbiologyevents.csv.gz\",\"poe\":\"poe.csv.gz\",\"prescriptions\":\"prescriptions.csv.gz\",\"services\":\"services.csv.gz\",\"diagnoses_icd\":\"diagnoses_icd.csv.gz\",\"d_icd_procedures\":\"d_icd_procedures.csv.gz\",\"drgcodes\":\"drgcodes.csv.gz\",\"emar_detail\":\"emar_detail.csv.gz\",\"labevents\":\"labevents.csv.gz\",\"pharmacy\":\"pharmacy.csv.gz\",\"poe_detail\":\"poe_detail.csv.gz\",\"procedures_icd\":\"procedures_icd.csv.gz\"}\n",
    "ed_filename_dict = {'diagnosis':'diagnosis.csv.gz', 'edstays':'edstays.csv.gz',  'medrecon':'medrecon.csv.gz',  'pyxis':'pyxis.csv.gz',  'triage':'triage.csv.gz',  'vitalsign':'vitalsign.csv.gz'}\n",
    "\n",
    "complaint_dict = {\"chiefcom_chest_pain\" : \"chest pain\", \"chiefcom_abdominal_pain\" : \"abdominal pain|abd pain\", \n",
    "\"chiefcom_headache\" : \"headache|lightheaded\", \"chiefcom_shortness_of_breath\" : \"breath\", \"chiefcom_back_pain\" : \"back pain\", \"chiefcom_cough\" : \"cough\", \n",
    "\"chiefcom_nausea_vomiting\" : \"nausea|vomit\", \"chiefcom_fever_chills\" : \"fever|chill\", \"chiefcom_syncope\" :\"syncope\", \"chiefcom_dizziness\" : \"dizz\"}\n",
    "\n",
    "# Defining parameters for the outcome variables\n",
    "icu_transfer_timerange = 12 # Considered critical outcome if patient is transferred to ICU within 12 hours of ED visit\n",
    "next_ed_visit_timerange = 3 # Considered an ED revisit if patient returns to ED within 3 days of discharge\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load raw data tables through pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading main tables\n",
    "df_edstays = read_edstays_table('/data/cb/scratch/sophia/rsidata/physionet.org/files/mimic-iv-ed/2.2/ed/edstays.csv.gz')\n",
    "df_patients = read_patients_table('/data/cb/scratch/sophia/rsidata/physionet.org/files/mimiciv/2.2/hosp/patients.csv.gz')\n",
    "df_admissions = read_admissions_table('/data/cb/scratch/sophia/rsidata/physionet.org/files/mimiciv/2.2/hosp/admissions.csv.gz')\n",
    "df_icustays = read_icustays_table('/data/cb/scratch/sophia/rsidata/physionet.org/files/mimiciv/2.2/icu/icustays.csv.gz')\n",
    "df_triage = read_triage_table('/data/cb/scratch/sophia/rsidata/physionet.org/files/mimic-iv-ed/2.2/ed/triage.csv.gz')\n",
    "df_vitalsign = read_vitalsign_table('/data/cb/scratch/sophia/rsidata/physionet.org/files/mimic-iv-ed/2.2/ed/vitalsign.csv.gz')\n",
    "df_pyxis = read_pyxis_table('/data/cb/scratch/sophia/rsidata/physionet.org/files/mimic-iv-ed/2.2/ed/pyxis.csv.gz')\n",
    "df_medrecon = read_pyxis_table('/data/cb/scratch/sophia/rsidata/physionet.org/files/mimic-iv-ed/2.2/ed/medrecon.csv.gz')\n",
    "\n",
    "## Read data here for ICD\n",
    "df_diagnoses = read_diagnoses_table('/data/cb/scratch/sophia/rsidata/physionet.org/files/mimiciv/2.2/hosp/diagnoses_icd.csv.gz')\n",
    "df_transfers = pd.read_csv('/data/cb/scratch/sophia/rsidata/physionet.org/files/mimiciv/2.2/hosp/transfers.csv.gz', compression='gzip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add demographics and outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging patients -> merging admissions -> merging triage -> master\n",
    "df_main = merge_edstays_patients_on_subject(df_edstays, df_patients)\n",
    "df_main = merge_edstays_admissions_on_subject(df_main, df_admissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x7fad13f3b7d0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 431231/431231 [06:38<00:00, 1081.47it/s]\n"
     ]
    }
   ],
   "source": [
    "transfers_with_hadm = df_transfers[df_transfers['hadm_id'].notna()]\n",
    "\n",
    "# Group by hadm_id to analyze patient journeys\n",
    "patient_journeys = transfers_with_hadm.groupby('hadm_id')\n",
    "# print(patient_journeys)\n",
    "\n",
    "# Find patients who meet our criteria:\n",
    "# 1. First admitted to non-ICU\n",
    "# 2. Later transferred to ICU\n",
    "icu_transfers = []\n",
    "\n",
    "import tqdm\n",
    "for (hadm_id, journey) in tqdm.tqdm(patient_journeys):\n",
    "    journey = journey.sort_values('intime')\n",
    "    \n",
    "    # Check if first admission is to non-ICU\n",
    "    first_admission = journey[journey['eventtype'] == 'admit'].iloc[0] if not journey[journey['eventtype'] == 'admit'].empty else None\n",
    "    \n",
    "    if first_admission is not None and 'ICU' not in str(first_admission['careunit']):\n",
    "        # Check if there's a later transfer to ICU\n",
    "        later_transfers = journey[(journey['eventtype'] == 'transfer') & \n",
    "                                 (journey['intime'] > first_admission['intime'])]\n",
    "        # print(\"later_transfers\", later_transfers)\n",
    "        \n",
    "        icu_transfers_in_journey = later_transfers[later_transfers['careunit'].str.contains('ICU', na=False)]\n",
    "\n",
    "        \n",
    "        if not icu_transfers_in_journey.empty:\n",
    "            # Add all relevant transfers to our list\n",
    "            icu_transfers.append(journey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process: 425087/425087\r"
     ]
    }
   ],
   "source": [
    "## Adding age, mortality and ICU transfer outcome\n",
    "df_main = add_age(df_main)\n",
    "df_main = add_inhospital_mortality(df_main)\n",
    "df_main = add_ed_los(df_main)\n",
    "df_main = add_outcome_icu_transfer(df_main, df_icustays, icu_transfer_timerange)\n",
    "df_main['outcome_hospitalization'] = ~pd.isnull(df_main['hadm_id'])\n",
    "df_main['mortality'] = df_main['outcome_inhospital_mortality']\n",
    "df_main['icuized'] = df_main[''.join(['outcome_icu_transfer_', str(icu_transfer_timerange), 'h'])]\n",
    "\n",
    "# Sort main table for further processing\n",
    "df_main = df_main.sort_values(['subject_id', 'intime']).reset_index()\n",
    "\n",
    "# Filling subjects NA ethnicity, takes ~17s\n",
    "df_main = fill_na_ethnicity(df_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify hadm_ids from icu_transfers (i.e., those who went to ICU after hospitalization)\n",
    "icu_transfer_hadm_ids = set()\n",
    "for journey in icu_transfers:\n",
    "    if 'hadm_id' in journey.columns:\n",
    "        icu_transfer_hadm_ids.update(journey['hadm_id'].unique())\n",
    "\n",
    "df_main['icu_direct'] = 0\n",
    "mask_icuized = df_main['icuized'] == True\n",
    "\n",
    "# ICUized + in icu_transfe\"r list -> icu_direct=0\n",
    "df_main.loc[mask_icuized & df_main['hadm_id'].isin(icu_transfer_hadm_ids), 'icu_direct'] = 0\n",
    "\n",
    "# ICUized + NOT in icu_transfer list -> icu_direct=1\n",
    "df_main.loc[mask_icuized & ~df_main['hadm_id'].isin(icu_transfer_hadm_ids), 'icu_direct'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "icu_direct\n",
       "False    425087\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main['icu_direct'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stage\n",
       "1    222071\n",
       "2    176427\n",
       "3     26589\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "hospitalized_and_icu = df_main[(df_main['outcome_hospitalization'] == True) & (df_main['icuized'] == True)]\n",
    "df_main['icu_direct'] = ((df_main['outcome_hospitalization'] == False) & (df_main['icuized'] == True))\n",
    "\n",
    "# New column: stage\n",
    "# 1 - not hospitalized and not icuized\n",
    "# 2 - hospitalized but not icuized\n",
    "# 3 - icuized\n",
    "df_main['stage'] = 1\n",
    "df_main.loc[(df_main['outcome_hospitalization'] == True) & (df_main['icuized'] == False), 'stage'] = 2\n",
    "df_main.loc[df_main['icuized'] == True, 'stage'] = 3\n",
    "\n",
    "df_main['stage'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triage Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging with triage table, cols of form triage_*\n",
    "df_main = merge_edstays_triage_on_subject(df_main, df_triage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding 10 chief complaints, chiefcom_*\n",
    "df_main = encode_chief_complaints(df_main, complaint_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>&lt; outlier_low</th>\n",
       "      <th>[outlier_low, valid_low)</th>\n",
       "      <th>[valid_low, valid_high]</th>\n",
       "      <th>(valid_high, outlier_high]</th>\n",
       "      <th>&gt; outlier_high</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>triage_temperature</td>\n",
       "      <td>479</td>\n",
       "      <td>29</td>\n",
       "      <td>401155</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>triage_heartrate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>407990</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>triage_resprate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>404731</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>triage_o2sat</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>404444</td>\n",
       "      <td>6</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>triage_sbp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>406780</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>triage_dbp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>405601</td>\n",
       "      <td>0</td>\n",
       "      <td>395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>triage_pain</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>386851</td>\n",
       "      <td>0</td>\n",
       "      <td>11205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>triage_acuity</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>418100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             variable < outlier_low [outlier_low, valid_low)  \\\n",
       "0  triage_temperature           479                       29   \n",
       "1    triage_heartrate             0                        0   \n",
       "2     triage_resprate             0                        0   \n",
       "3        triage_o2sat             0                        0   \n",
       "4          triage_sbp             0                        0   \n",
       "5          triage_dbp             0                        0   \n",
       "6         triage_pain             0                        0   \n",
       "7       triage_acuity             0                        0   \n",
       "\n",
       "  [valid_low, valid_high] (valid_high, outlier_high] > outlier_high  \n",
       "0                  401155                          0              9  \n",
       "1                  407990                          0              7  \n",
       "2                  404731                          0              3  \n",
       "3                  404444                          6             41  \n",
       "4                  406780                          0             16  \n",
       "5                  405601                          0            395  \n",
       "6                  386851                          0          11205  \n",
       "7                  418100                          0              0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from helpers import vitals_valid_range\n",
    "\n",
    "df_main = convert_temp_to_celsius(df_main)\n",
    "display_outliers_count(df_main, vitals_valid_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_normalize = [\n",
    "    'triage_temperature',\n",
    "    'triage_heartrate',\n",
    "    'triage_resprate',\n",
    "    'triage_o2sat',\n",
    "    'triage_sbp',\n",
    "    'triage_dbp',\n",
    "    'triage_pain',\n",
    "    'triage_acuity'\n",
    "]\n",
    "\n",
    "for feat in features_to_normalize:\n",
    "    mean = df_main[feat].mean(skipna=True)\n",
    "    std = df_main[feat].std(skipna=True)\n",
    "    z_col = f\"{feat}_z\"\n",
    "    sq_col = f\"{feat}_sq\"\n",
    "    # z-score\n",
    "    df_main[z_col] = (df_main[feat] - mean) / std\n",
    "    # impute mean for missing values\n",
    "    df_main[z_col] = df_main[z_col].fillna(0)  # mean of z-score is 0\n",
    "    # add squared column\n",
    "    df_main[sq_col] = df_main[z_col] ** 2\n",
    "\n",
    "df_main['intercept'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coarse_race\n",
       "WHITE                     247459\n",
       "BLACK/AFRICAN AMERICAN     92998\n",
       "HISPANIC OR LATINO         35574\n",
       "OTHER                      30528\n",
       "ASIAN                      18528\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "granular_to_coarse = {\n",
    "    'HISPANIC/LATINO - PUERTO RICAN': 'HISPANIC OR LATINO', \n",
    "    'HISPANIC/LATINO - DOMINICAN': 'HISPANIC OR LATINO', \n",
    "    'HISPANIC/LATINO - GUATEMALAN': 'HISPANIC OR LATINO', \n",
    "    'HISPANIC/LATINO - SALVADORAN': 'HISPANIC OR LATINO', \n",
    "    'HISPANIC/LATINO - MEXICAN': 'HISPANIC OR LATINO', \n",
    "    'HISPANIC/LATINO - COLUMBIAN': 'HISPANIC OR LATINO', \n",
    "    'HISPANIC/LATINO - HONDURAN': 'HISPANIC OR LATINO', \n",
    "    'HISPANIC/LATINO - CUBAN': 'HISPANIC OR LATINO',\n",
    "    'HISPANIC/LATINO - CENTRAL AMERICAN': 'HISPANIC OR LATINO',\n",
    "    'SOUTH AMERICAN': 'HISPANIC OR LATINO',\n",
    "    'ASIAN - CHINESE': 'ASIAN',\n",
    "    'ASIAN - SOUTH EAST ASIAN': 'ASIAN',\n",
    "    'ASIAN - ASIAN INDIAN': 'ASIAN',\n",
    "    'ASIAN - KOREAN': 'ASIAN',\n",
    "    'WHITE - OTHER EUROPEAN': 'WHITE',\n",
    "    'WHITE - RUSSIAN': 'WHITE',\n",
    "    'WHITE - EASTERN EUROPEAN': 'WHITE',\n",
    "    'WHITE - BRAZILIAN': 'WHITE',\n",
    "    'PORTUGUESE': 'WHITE',\n",
    "    'BLACK/CAPE VERDEAN': 'BLACK/AFRICAN AMERICAN',\n",
    "    'BLACK/CARIBBEAN ISLAND': 'BLACK/AFRICAN AMERICAN',\n",
    "    'BLACK/AFRICAN': 'BLACK/AFRICAN AMERICAN',\n",
    "    'AMERICAN INDIAN/ALASKA NATIVE': 'OTHER',\n",
    "    'NATIVE HAWAIIAN OR OTHER PACIFIC ISLANDER': 'OTHER',\n",
    "    'MULTIPLE RACE/ETHNICITY': 'OTHER',\n",
    "    'UNKNOWN': 'OTHER',\n",
    "    'PATIENT DECLINED TO ANSWER': 'OTHER',\n",
    "    'UNABLE TO OBTAIN': 'OTHER',\n",
    "}\n",
    "\n",
    "'''\n",
    "Input: patient reported race recorded in MIMIC-IV\n",
    "Output: \n",
    "If the reported race is granular, then return its coarse category;\n",
    "else, return the reported (coarse) race.\n",
    "\n",
    "The goal is to construct a coarse race column for all patients.\n",
    "'''\n",
    "def coarsen_race(race):\n",
    "    if race in granular_to_coarse: return granular_to_coarse[race]\n",
    "    else: return race\n",
    "\n",
    "df_main.insert(7, 'coarse_race', df_main['race'].apply(coarsen_race))\n",
    "# df_main.rename(columns={'race': 'granular_race'}, inplace=True)\n",
    "df_main['coarse_race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_main.to_csv('mimic_cleaned.csv', index=False)\n",
    "list(df_main.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "numpyro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
